{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m020\u001b[0m (\u001b[33msnehalma23m020-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 10:20:57.379653: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 10:20:57.386694: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-06 10:20:57.477897: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-06 10:20:57.569399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741236657.653655    5333 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741236657.674495    5333 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 10:20:57.860559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "#Class names for the Fashion-MNIST labels\n",
    "CLASS_NAMES = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting one image per class\n",
    "def plot_one_sample_per_class(X, y, class_names):\n",
    "    plotted_classes = set()\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        label = y[i]\n",
    "        if label not in plotted_classes:\n",
    "            plotted_classes.add(label)\n",
    "            count += 1\n",
    "            plt.subplot(2, 5, count)\n",
    "            plt.imshow(X[i], cmap=\"CMRmap\") # try Blues, gray\n",
    "            plt.title(class_names[label])\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            if count == 10:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_one_sample_per_class(X_train, y_train, CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_102406-h7se57at</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/h7se57at' target=\"_blank\">question_1</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/h7se57at' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/h7se57at</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">question_1</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/h7se57at' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/h7se57at</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 36 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_102406-h7se57at/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"DLassignment1\", name=\"question_1\")\n",
    "\n",
    "set1_images = []\n",
    "set2_images = []\n",
    "\n",
    "for i in range(18):\n",
    "    set1_images.append(wandb.Image(X_train[i], caption=f\"{CLASS_NAMES[y_train[i]]} (idx={i})\"))\n",
    "\n",
    "for i in range(18, 36):\n",
    "    set2_images.append(wandb.Image(X_train[i], caption=f\"{CLASS_NAMES[y_train[i]]} (idx={i})\"))\n",
    "\n",
    "wandb.log({\"Set 1\": set1_images, \"Set 2\": set2_images})\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 16:14:05.630849: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 16:14:05.637320: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-08 16:14:05.696657: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-08 16:14:05.752604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741430645.802561   59511 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741430645.816917   59511 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 16:14:05.929744: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import fashion_mnist # loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "y_train = one_hot_encode(y_train)\n",
    "y_test = one_hot_encode(y_test)\n",
    "\n",
    "# Neural Network Class\n",
    "class FeedforwardNN:\n",
    "    def __init__(self, input_size, hidden_layers, output_size=10, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = [input_size] + hidden_layers + [output_size]\n",
    "        self.weights = {}\n",
    "        self.biases = {}\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.weights[i] = np.random.randn(self.layers[i], self.layers[i + 1]) * 0.01\n",
    "            self.biases[i] = np.zeros((1, self.layers[i + 1]))\n",
    "    \n",
    "    def relu(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def relu_derivative(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        cache = {'A0': X}\n",
    "        A = X\n",
    "        \n",
    "        for i in range(len(self.layers) - 2):\n",
    "            Z = np.dot(A, self.weights[i]) + self.biases[i]\n",
    "            A = self.relu(Z)\n",
    "            cache[f'Z{i+1}'] = Z\n",
    "            cache[f'A{i+1}'] = A\n",
    "        \n",
    "        Z_final = np.dot(A, self.weights[len(self.layers)-2]) + self.biases[len(self.layers)-2]\n",
    "        A_final = self.softmax(Z_final)\n",
    "        \n",
    "        cache[f'Z{len(self.layers)-1}'] = Z_final\n",
    "        cache[f'A{len(self.layers)-1}'] = A_final\n",
    "        \n",
    "        return A_final, cache\n",
    "    \n",
    "    def compute_loss(self, Y_pred, Y_true):\n",
    "        m = Y_true.shape[0]\n",
    "        loss = -np.sum(Y_true * np.log(Y_pred + 1e-8)) / m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, cache, X, Y):\n",
    "        m = X.shape[0]\n",
    "        grads = {}\n",
    "        \n",
    "        dZ = cache[f'A{len(self.layers)-1}'] - Y\n",
    "        \n",
    "        for i in reversed(range(len(self.layers) - 1)):\n",
    "            dW = (1/m) * np.dot(cache[f'A{i}'].T, dZ)\n",
    "            db = (1/m) * np.sum(dZ, axis=0, keepdims=True)\n",
    "            \n",
    "            grads[f'dW{i}'] = dW\n",
    "            grads[f'db{i}'] = db\n",
    "            \n",
    "            if i > 0:\n",
    "                dZ = np.dot(dZ, self.weights[i].T) * self.relu_derivative(cache[f'Z{i}'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def update_parameters(self, grads):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.weights[i] -= self.learning_rate * grads[f'dW{i}']\n",
    "            self.biases[i] -= self.learning_rate * grads[f'db{i}']\n",
    "    \n",
    "    def train(self, X, Y, epochs=10, batch_size=64):\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.arange(X.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X, Y = X[indices], Y[indices]\n",
    "            \n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                X_batch = X[i:i+batch_size]\n",
    "                Y_batch = Y[i:i+batch_size]\n",
    "                \n",
    "                Y_pred, cache = self.forward(X_batch)\n",
    "                grads = self.backward(cache, X_batch, Y_batch)\n",
    "                self.update_parameters(grads)\n",
    "            \n",
    "            if epoch % 2 == 0:\n",
    "                loss = self.compute_loss(Y_pred, Y_batch)\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y_pred, _ = self.forward(X)\n",
    "        return np.argmax(Y_pred, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, Y):\n",
    "        Y_pred = self.predict(X)\n",
    "        Y_true = np.argmax(Y, axis=1)\n",
    "        return np.mean(Y_pred == Y_true)\n",
    "\n",
    "# Model Configuration\n",
    "input_size = 784\n",
    "hidden_layers = [128, 64]\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "dnn = FeedforwardNN(input_size, hidden_layers, output_size, learning_rate)\n",
    "\n",
    "dnn.train(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "test_acc = dnn.accuracy(x_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_102546-eyq8mk53</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/eyq8mk53' target=\"_blank\">unique-plasma-35</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/eyq8mk53' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/eyq8mk53</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes:\n",
      " X_train: (60000, 28, 28)\n",
      " y_train: (60000,)\n",
      " X_test:  (10000, 28, 28)\n",
      " y_test:  (10000,)\n",
      "\n",
      "After reshaping & normalization:\n",
      " X_train: (60000, 784)\n",
      " X_test:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Initialize Weights & Biases (wandb)\n",
    "wandb.init(project=\"DLassignment1\")\n",
    "\n",
    "# Load Fashion-MNIST Dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(\" X_train:\", X_train.shape)  # (60000, 28, 28)\n",
    "print(\" y_train:\", y_train.shape)  # (60000,)\n",
    "print(\" X_test: \", X_test.shape)   # (10000, 28, 28)\n",
    "print(\" y_test: \", y_test.shape)   # (10000,)\n",
    "\n",
    "# Reshape: 28x28 -> 784\n",
    "X_train = X_train.reshape(-1, 28*28).astype(np.float32)\n",
    "X_test  = X_test.reshape(-1, 28*28).astype(np.float32)\n",
    "\n",
    "# Normalize pixel values to [0,1]\n",
    "X_train /= 255.0\n",
    "X_test  /= 255.0\n",
    "\n",
    "print(\"\\nAfter reshaping & normalization:\")\n",
    "print(\" X_train:\", X_train.shape)  # (60000, 784)\n",
    "print(\" X_test: \", X_test.shape)   # (10000, 784)\n",
    "\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 10\n",
    "y_train_onehot = np.eye(num_classes)[y_train]\n",
    "y_test_onehot = np.eye(num_classes)[y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_oh shape: (60000, 10)\n",
      "y_test_oh shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts a 1D array of labels into a 2D one-hot encoded array.\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((labels.shape[0], num_classes))\n",
    "    one_hot[np.arange(labels.shape[0]), labels] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "y_train_oh = one_hot_encode(y_train, 10)\n",
    "y_test_oh  = one_hot_encode(y_test, 10)\n",
    "\n",
    "print(\"y_train_oh shape:\", y_train_oh.shape)  # (60000, 10)\n",
    "print(\"y_test_oh shape: \", y_test_oh.shape)   # (10000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"ReLU activation: max(0, Z).\"\"\"\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    \"\"\"Derivative of ReLU w.r.t. Z (returns 1 where Z > 0).\"\"\"\n",
    "    return (Z > 0).astype(Z.dtype)\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"Softmax activation for output layer.\"\"\"\n",
    "    shiftZ = Z - np.max(Z, axis=1, keepdims=True)  # for numerical stability\n",
    "    expZ = np.exp(shiftZ)\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(probs, one_hot_labels):\n",
    "    \"\"\"\n",
    "    Cross-entropy loss for multi-class classification.\n",
    "      - probs: (N, 10) softmax outputs\n",
    "      - one_hot_labels: (N, 10)\n",
    "    \"\"\"\n",
    "    eps = 1e-9\n",
    "    log_probs = -np.log(probs + eps)\n",
    "    return np.mean(np.sum(log_probs * one_hot_labels, axis=1))\n",
    "\n",
    "def accuracy(probs, one_hot_labels):\n",
    "    \"\"\"Computes accuracy from predicted probabilities and one-hot labels.\"\"\"\n",
    "    pred_labels = np.argmax(probs, axis=1)\n",
    "    true_labels = np.argmax(one_hot_labels, axis=1)\n",
    "    return np.mean(pred_labels == true_labels)\n",
    "\n",
    "def initialize_parameters(layer_sizes):\n",
    "    \"\"\"\n",
    "    layer_sizes: List of dimensions, e.g. [784, 128, 64, 10].\n",
    "    Returns a dictionary with weights W1, W2, ... and biases b1, b2, ...\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # for reproducibility\n",
    "    params = {}\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        in_size = layer_sizes[i]\n",
    "        out_size = layer_sizes[i+1]\n",
    "        # He initialization for layers with ReLU activation\n",
    "        params[f\"W{i+1}\"] = np.random.randn(in_size, out_size) * np.sqrt(2.0 / in_size)\n",
    "        params[f\"b{i+1}\"] = np.zeros((1, out_size))\n",
    "    return params\n",
    "\n",
    "def forward_pass(X, params, layer_sizes):\n",
    "    \"\"\"\n",
    "    X: (N, input_size) input data\n",
    "    params: Dictionary of weights and biases\n",
    "    layer_sizes: e.g. [784, 128, 64, 10]\n",
    "    \n",
    "    Returns:\n",
    "      - probs: (N, 10) final softmax output.\n",
    "      - cache: Dictionary of intermediate values (Z and A for each layer).\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "    A = X  # input activation\n",
    "    num_layers = len(layer_sizes) - 1\n",
    "    for i in range(num_layers):\n",
    "        W = params[f\"W{i+1}\"]\n",
    "        b = params[f\"b{i+1}\"]\n",
    "        Z = A @ W + b\n",
    "        cache[f\"Z{i+1}\"] = Z\n",
    "        if i < num_layers - 1:\n",
    "            # Hidden layer: use ReLU activation\n",
    "            A = relu(Z)\n",
    "        else:\n",
    "            # Output layer: use softmax activation\n",
    "            A = softmax(Z)\n",
    "        cache[f\"A{i+1}\"] = A\n",
    "    probs = A\n",
    "    return probs, cache\n",
    "\n",
    "def backward_pass(X, y_true, params, cache, layer_sizes):\n",
    "    \"\"\"\n",
    "    X: (N, input_size) input data.\n",
    "    y_true: (N, 10) one-hot labels.\n",
    "    params: Dictionary of weights and biases.\n",
    "    cache: Dictionary of intermediate values from forward_pass.\n",
    "    layer_sizes: List, e.g. [784, 128, 64, 10].\n",
    "    \n",
    "    Returns:\n",
    "      grads: Dictionary containing gradients for W and b for each layer.\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    N = X.shape[0]\n",
    "    num_layers = len(layer_sizes) - 1  # number of layers with parameters\n",
    "    \n",
    "    # --- Output Layer ---\n",
    "    i = num_layers - 1  # index for output layer (e.g., 2 for a network with 3 layers)\n",
    "    A_out = cache[f\"A{i+1}\"]  # softmax output, shape (N, 10)\n",
    "    # For softmax-crossentropy, dZ = A_out - y_true\n",
    "    dZ = A_out - y_true  # shape (N, 10)\n",
    "    if i == 0:\n",
    "        A_prev = X\n",
    "    else:\n",
    "        A_prev = cache[f\"A{i}\"]\n",
    "    grads[f\"dW{i+1}\"] = (A_prev.T @ dZ) / N\n",
    "    grads[f\"db{i+1}\"] = np.sum(dZ, axis=0, keepdims=True) / N\n",
    "    \n",
    "    # --- Hidden Layers ---\n",
    "    # Propagate gradient backwards for hidden layers (from layer num_layers-2 down to 0)\n",
    "    for i in reversed(range(num_layers - 1)):\n",
    "        # Propagate through layer i+1 to get gradients for layer i\n",
    "        # Use weights from the layer ahead: W{i+2}\n",
    "        W_next = params[f\"W{i+2}\"]\n",
    "        dA = dZ @ W_next.T  # shape: (N, layer_sizes[i+1])\n",
    "        Z_curr = cache[f\"Z{i+1}\"]\n",
    "        dZ = dA * relu_derivative(Z_curr)  # derivative through ReLU\n",
    "        if i == 0:\n",
    "            A_prev = X\n",
    "        else:\n",
    "            A_prev = cache[f\"A{i}\"]\n",
    "        grads[f\"dW{i+1}\"] = (A_prev.T @ dZ) / N\n",
    "        grads[f\"db{i+1}\"] = np.sum(dZ, axis=0, keepdims=True) / N\n",
    "    \n",
    "    return grads\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Updates parameters using gradient descent.\n",
    "    \"\"\"\n",
    "    for key in params.keys():\n",
    "        if key.startswith(\"W\"):\n",
    "            i = key[1:]  # extract layer number from key \"W1\", \"W2\", etc.\n",
    "            params[key] -= learning_rate * grads[f\"dW{i}\"]\n",
    "        elif key.startswith(\"b\"):\n",
    "            i = key[1:]\n",
    "            params[key] -= learning_rate * grads[f\"db{i}\"]\n",
    "    return params\n",
    "\n",
    "def train_network(\n",
    "    X_train, y_train_oh,\n",
    "    X_test, y_test_oh,\n",
    "    layer_sizes,\n",
    "    epochs=10,\n",
    "    learning_rate=0.01,\n",
    "    project_name=\"DL_Assignment1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the feedforward neural network (pure NumPy) on Fashion-MNIST.\n",
    "    Logs training and test metrics to Weights & Biases.\n",
    "    \n",
    "    Args:\n",
    "      - X_train, y_train_oh: Training data and one-hot labels.\n",
    "      - X_test, y_test_oh: Test data and one-hot labels.\n",
    "      - layer_sizes: List of layer dimensions, e.g. [784, 128, 64, 10].\n",
    "      - epochs: Number of training epochs.\n",
    "      - learning_rate: Learning rate for gradient descent.\n",
    "      - project_name: W&B project name (string).\n",
    "    \n",
    "    Returns:\n",
    "      - params: Trained network parameters.\n",
    "    \"\"\"\n",
    "    # Initialize a new W&B run (ensure wandb.login() is done in an earlier cell)\n",
    "    wandb.init(project=project_name, name=\"feedforward_numpy_network\")\n",
    "    \n",
    "    # Initialize network parameters\n",
    "    params = initialize_parameters(layer_sizes)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass on training data\n",
    "        probs_train, cache_train = forward_pass(X_train, params, layer_sizes)\n",
    "        train_loss = cross_entropy_loss(probs_train, y_train_oh)\n",
    "        train_acc  = accuracy(probs_train, y_train_oh)\n",
    "        \n",
    "        # Backward pass\n",
    "        grads_train = backward_pass(X_train, y_train_oh, params, cache_train, layer_sizes)\n",
    "        \n",
    "        # Update parameters\n",
    "        params = update_parameters(params, grads_train, learning_rate)\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        probs_test, _ = forward_pass(X_test, params, layer_sizes)\n",
    "        test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "        test_acc  = accuracy(probs_test, y_test_oh)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        \n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "    \n",
    "    wandb.finish()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10\n",
    "def train_network(\n",
    "    X_train, y_train_oh,\n",
    "    X_test, y_test_oh,\n",
    "    layer_sizes,\n",
    "    epochs=10,\n",
    "    learning_rate=0.01,\n",
    "    project_name=\"DL_Assignment1\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the feedforward NN on Fashion-MNIST in pure NumPy.\n",
    "    Logs metrics to Weights & Biases (W&B).\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train_oh: training data & one-hot labels\n",
    "        X_test, y_test_oh: test data & one-hot labels\n",
    "        layer_sizes: e.g. [784, 128, 64, 10]\n",
    "        epochs: number of training epochs\n",
    "        learning_rate: gradient descent LR\n",
    "        project_name: W&B project name for logging\n",
    "    \"\"\"\n",
    "    # 1) Initialize W&B run\n",
    "    wandb.init(project=DL_Assignment1, name=\"feedforward\")\n",
    "    \n",
    "    # 2) Initialize parameters\n",
    "    params = initialize_parameters(layer_sizes)\n",
    "    \n",
    "    # 3) Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        probs_train, cache_train = forward_pass(X_train, params, layer_sizes)\n",
    "        train_loss = cross_entropy_loss(probs_train, y_train_oh)\n",
    "        train_acc  = accuracy(probs_train, y_train_oh)\n",
    "        \n",
    "        # Backward pass\n",
    "        grads_train = backward_pass(X_train, y_train_oh, params, cache_train, layer_sizes)\n",
    "        \n",
    "        # Update\n",
    "        params = update_parameters(params, grads_train, learning_rate)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        probs_test, _ = forward_pass(X_test, params, layer_sizes)\n",
    "        test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "        test_acc  = accuracy(probs_test, y_test_oh)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        \n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "    \n",
    "    # 4) Finish W&B run\n",
    "    wandb.finish()\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard SGD\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                params[key] -= self.lr * grads[key]\n",
    "        return params\n",
    "\n",
    "# Momentum-based gradient descent\n",
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}  # velocity dictionary\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                self.v[key] = self.momentum * self.v[key] + self.lr * grads[key]\n",
    "                params[key] -= self.v[key]\n",
    "        return params\n",
    "\n",
    "# Nesterov Accelerated Gradient Descent\n",
    "class Nesterov:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                v_prev = self.v[key].copy()\n",
    "                # Standard momentum update in Nesterov form\n",
    "                self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
    "                # Nesterov update uses a lookahead: update using v_prev and new v\n",
    "                params[key] += -self.momentum * v_prev + (1 + self.momentum) * self.v[key]\n",
    "        return params\n",
    "\n",
    "# RMSprop optimizer\n",
    "class RMSprop:\n",
    "    def __init__(self, lr=0.001, decay_rate=0.99, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.cache = {}\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.cache:\n",
    "                    self.cache[key] = np.zeros_like(params[key])\n",
    "                self.cache[key] = self.decay_rate * self.cache[key] + (1 - self.decay_rate) * (grads[key]**2)\n",
    "                params[key] -= self.lr * grads[key] / (np.sqrt(self.cache[key]) + self.epsilon)\n",
    "        return params\n",
    "\n",
    "# Adam optimizer\n",
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = {}\n",
    "        self.v = {}\n",
    "    def update(self, params, grads, t):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.m:\n",
    "                    self.m[key] = np.zeros_like(params[key])\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n",
    "                self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key]**2)\n",
    "                m_hat = self.m[key] / (1 - self.beta1**t)\n",
    "                v_hat = self.v[key] / (1 - self.beta2**t)\n",
    "                params[key] -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        return params\n",
    "\n",
    "# Nadam optimizer (Adam with Nesterov momentum)\n",
    "class Nadam:\n",
    "    def __init__(self, lr=0.002, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = {}\n",
    "        self.v = {}\n",
    "    def update(self, params, grads, t):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.m:\n",
    "                    self.m[key] = np.zeros_like(params[key])\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n",
    "                self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key]**2)\n",
    "                m_hat = self.m[key] / (1 - self.beta1**t)\n",
    "                v_hat = self.v[key] / (1 - self.beta2**t)\n",
    "                # Nadam update: combines Adam with Nesterov momentum\n",
    "                params[key] -= self.lr * ((self.beta1 * m_hat + (1 - self.beta1) * grads[key] / (1 - self.beta1**t))\n",
    "                                          / (np.sqrt(v_hat) + self.epsilon))\n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_batch(X_train, y_train_oh, X_test, y_test_oh,\n",
    "                        layer_sizes, optimizer, epochs=10, batch_size=64,\n",
    "                        project_name=\"DL_Assignment1\"):\n",
    "    \"\"\"\n",
    "    Trains the feedforward NN using mini-batch gradient descent.\n",
    "    \n",
    "    Args:\n",
    "      X_train, y_train_oh: Training data and one-hot labels.\n",
    "      X_test, y_test_oh: Test data and one-hot labels.\n",
    "      layer_sizes: List of layer sizes, e.g. [784, 128, 64, 10].\n",
    "      optimizer: An instance of one of the optimizer classes (e.g. SGD, Adam, etc.).\n",
    "      epochs: Number of epochs.\n",
    "      batch_size: Mini-batch size.\n",
    "      project_name: W&B project name (string).\n",
    "      \n",
    "    Returns:\n",
    "      params: Trained network parameters.\n",
    "    \"\"\"\n",
    "    # Initialize a new W&B run (ensure wandb.login() was run earlier)\n",
    "    wandb.init(project=project_name, name=f\"{optimizer.__class__.__name__}_run\")\n",
    "    \n",
    "    params = initialize_parameters(layer_sizes)\n",
    "    t = 0  # global iteration counter\n",
    "    N = X_train.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = np.random.permutation(N)\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train_oh[permutation]\n",
    "        \n",
    "        # Process mini-batches\n",
    "        for i in range(0, N, batch_size):\n",
    "            t += 1\n",
    "            X_batch = X_train_shuffled[i:i+batch_size]\n",
    "            y_batch = y_train_shuffled[i:i+batch_size]\n",
    "            \n",
    "            probs, cache = forward_pass(X_batch, params, layer_sizes)\n",
    "            grads = backward_pass(X_batch, y_batch, params, cache, layer_sizes)\n",
    "            # Use the chosen optimizer to update parameters\n",
    "            # For optimizers like Adam/Nadam, pass the iteration count t\n",
    "            params = optimizer.update(params, grads, t)\n",
    "        \n",
    "        # End-of-epoch evaluation on full training and test sets\n",
    "        probs_train, _ = forward_pass(X_train, params, layer_sizes)\n",
    "        train_loss = cross_entropy_loss(probs_train, y_train_oh)\n",
    "        train_acc = accuracy(probs_train, y_train_oh)\n",
    "        \n",
    "        probs_test, _ = forward_pass(X_test, params, layer_sizes)\n",
    "        test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "        test_acc = accuracy(probs_test, y_test_oh)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "        \n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        })\n",
    "        \n",
    "    wandb.finish()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_103544-txim0266</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/txim0266' target=\"_blank\">SGD_run</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/txim0266' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/txim0266</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 2/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 3/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 4/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 5/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 6/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 7/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 8/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 9/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 10/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 11/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 12/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 13/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 14/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 15/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 16/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 17/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 18/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 19/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 20/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 21/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 22/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 23/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 24/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 25/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 26/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 27/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 28/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 29/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 30/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 31/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 32/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 33/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 34/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 35/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 36/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 37/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 38/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 39/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 40/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 41/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 42/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 43/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 44/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 45/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 46/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 47/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 48/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 49/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n",
      "Epoch 50/50 | Train Loss: 2.4500, Train Acc: 0.1179 | Test Loss: 2.4440, Test Acc: 0.1208\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>test_acc</td><td>0.1208</td></tr><tr><td>test_loss</td><td>2.44401</td></tr><tr><td>train_acc</td><td>0.1179</td></tr><tr><td>train_loss</td><td>2.45002</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">SGD_run</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/txim0266' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/txim0266</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_103544-txim0266/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log in to W&B (run this cell once per session)\n",
    "wandb.login()\n",
    "\n",
    "# Define network architecture\n",
    "layer_sizes = [784, 128, 64, 10]\n",
    "\n",
    "# Choose an optimizer (change to SGD, Momentum, Nesterov, RMSprop, Adam, or Nadam)\n",
    "# For example, using Adam:\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "# Train the network with mini-batch training\n",
    "trained_params = train_network_batch(\n",
    "    X_train, y_train_oh,\n",
    "    X_test, y_test_oh,\n",
    "    layer_sizes=layer_sizes,\n",
    "    optimizer=optimizer,\n",
    "    epochs=50,\n",
    "    batch_size=32, \n",
    "    project_name=\"DLassignment1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 2.4440\n",
      "Final Test Accuracy: 0.1208\n"
     ]
    }
   ],
   "source": [
    "probs_test, _ = forward_pass(X_test, trained_params, layer_sizes)\n",
    "final_test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "final_test_acc = accuracy(probs_test, y_test_oh)\n",
    "print(f\"Final Test Loss: {final_test_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "def load_data(val_split=0.1):\n",
    "    \"\"\"\n",
    "    Loads Fashion-MNIST, reshapes & normalizes it, and splits off 'val_split' fraction\n",
    "    of the training data as validation data.\n",
    "    Returns: (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "    \"\"\"\n",
    "    (X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    # Flatten 28x28 => 784, normalize\n",
    "    X_train_full = X_train_full.reshape(-1, 784).astype(np.float32) / 255.0\n",
    "    X_test       = X_test.reshape(-1, 784).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Reserve 10% of training data for validation\n",
    "    val_size = int(val_split * len(X_train_full))\n",
    "    X_val = X_train_full[:val_size]\n",
    "    y_val = y_train_full[:val_size]\n",
    "    X_train = X_train_full[val_size:]\n",
    "    y_train = y_train_full[val_size:]\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts a 1D array of labels (0..9) into a 2D one-hot encoded array.\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((labels.shape[0], num_classes))\n",
    "    one_hot[np.arange(labels.shape[0]), labels] = 1.0\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return (Z > 0).astype(Z.dtype)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_derivative(A):\n",
    "    # If A = sigmoid(Z), derivative wrt Z is A*(1-A)\n",
    "    return A*(1 - A)\n",
    "\n",
    "def tanh(Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "def tanh_derivative(A):\n",
    "    # If A = tanh(Z), derivative wrt Z is 1 - A^2\n",
    "    return 1 - A**2\n",
    "\n",
    "def softmax(Z):\n",
    "    shiftZ = Z - np.max(Z, axis=1, keepdims=True)\n",
    "    expZ = np.exp(shiftZ)\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(probs, one_hot_labels):\n",
    "    eps = 1e-9\n",
    "    log_probs = -np.log(probs + eps)\n",
    "    return np.mean(np.sum(log_probs * one_hot_labels, axis=1))\n",
    "\n",
    "def accuracy(probs, one_hot_labels):\n",
    "    pred_labels = np.argmax(probs, axis=1)\n",
    "    true_labels = np.argmax(one_hot_labels, axis=1)\n",
    "    return np.mean(pred_labels == true_labels)\n",
    "\n",
    "\n",
    "def xavier_init(in_dim, out_dim):\n",
    "    # Xavier uniform\n",
    "    limit = np.sqrt(6.0 / (in_dim + out_dim))\n",
    "    return np.random.uniform(-limit, limit, (in_dim, out_dim))\n",
    "\n",
    "def random_init(in_dim, out_dim):\n",
    "    # Basic random normal scaled by 0.01\n",
    "    return 0.01 * np.random.randn(in_dim, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "\n",
    "def initialize_parameters(input_dim, num_hidden_layers, hidden_size, output_dim,\n",
    "                          weight_init=\"random\"):\n",
    "    \"\"\"\n",
    "    Creates parameter dict: W1, b1, W2, b2, ..., WL, bL\n",
    "    Where L = num_hidden_layers + 1 (the output layer)\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    prev_dim = input_dim\n",
    "    \n",
    "    for i in range(num_hidden_layers):\n",
    "        layer_name = i+1\n",
    "        if weight_init == \"xavier\":\n",
    "            params[f\"W{layer_name}\"] = xavier_init(prev_dim, hidden_size)\n",
    "        else:  # \"random\"\n",
    "            params[f\"W{layer_name}\"] = random_init(prev_dim, hidden_size)\n",
    "        params[f\"b{layer_name}\"] = np.zeros((1, hidden_size))\n",
    "        prev_dim = hidden_size\n",
    "    \n",
    "    # Output layer\n",
    "    layer_name = num_hidden_layers + 1\n",
    "    if weight_init == \"xavier\":\n",
    "        params[f\"W{layer_name}\"] = xavier_init(prev_dim, output_dim)\n",
    "    else:\n",
    "        params[f\"W{layer_name}\"] = random_init(prev_dim, output_dim)\n",
    "    params[f\"b{layer_name}\"] = np.zeros((1, output_dim))\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def forward_pass(X, params, num_hidden_layers, activation):\n",
    "    \"\"\"\n",
    "    Forward pass through the network. \n",
    "    activation in {\"relu\", \"sigmoid\", \"tanh\"} for hidden layers.\n",
    "    Softmax output layer.\n",
    "    Returns final probs and a cache of intermediate values.\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "    A = X\n",
    "    L = num_hidden_layers + 1  # total layers\n",
    "    \n",
    "    for i in range(1, L+1):\n",
    "        W = params[f\"W{i}\"]\n",
    "        b = params[f\"b{i}\"]\n",
    "        Z = A @ W + b\n",
    "        \n",
    "        if i < L:\n",
    "            # Hidden layer\n",
    "            if activation == \"relu\":\n",
    "                A = relu(Z)\n",
    "            elif activation == \"sigmoid\":\n",
    "                A = sigmoid(Z)\n",
    "            else: # \"tanh\"\n",
    "                A = tanh(Z)\n",
    "            cache[f\"Z{i}\"] = Z\n",
    "            cache[f\"A{i}\"] = A\n",
    "        else:\n",
    "            # Output layer => softmax\n",
    "            probs = softmax(Z)\n",
    "            cache[f\"Z{i}\"] = Z\n",
    "            cache[f\"A{i}\"] = probs\n",
    "    \n",
    "    return probs, cache\n",
    "\n",
    "\n",
    "def backward_pass(X, y, params, cache, num_hidden_layers, activation):\n",
    "    \"\"\"\n",
    "    Backprop through the network:\n",
    "      X: input batch\n",
    "      y: one-hot labels\n",
    "      cache: forward-pass intermediates\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = num_hidden_layers + 1\n",
    "    m = X.shape[0]  # batch size\n",
    "    \n",
    "    # 1) Output layer gradient\n",
    "    A_out = cache[f\"A{L}\"]      # (m, 10)\n",
    "    dZ = A_out - y              # derivative wrt Z in output layer\n",
    "    # A_{L-1} is the activation from the last hidden layer (or X if only 1 layer)\n",
    "    A_prev = cache[f\"A{L-1}\"] if L > 1 else X\n",
    "    grads[f\"dW{L}\"] = (A_prev.T @ dZ) / m\n",
    "    grads[f\"db{L}\"] = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "    \n",
    "    # 2) Hidden layers (in reverse)\n",
    "    for i in reversed(range(1, L)):\n",
    "        W_next = params[f\"W{i+1}\"]\n",
    "        Z_curr = cache[f\"Z{i}\"]\n",
    "        if i == 1:\n",
    "            A_prev = X\n",
    "        else:\n",
    "            A_prev = cache[f\"A{i-1}\"]\n",
    "        \n",
    "        dA = dZ @ W_next.T\n",
    "        # derivative depends on activation\n",
    "        if activation == \"relu\":\n",
    "            dZ = dA * relu_derivative(Z_curr)\n",
    "        elif activation == \"sigmoid\":\n",
    "            A_curr = cache[f\"A{i}\"]\n",
    "            dZ = dA * sigmoid_derivative(A_curr)\n",
    "        else:  # \"tanh\"\n",
    "            A_curr = cache[f\"A{i}\"]\n",
    "            dZ = dA * tanh_derivative(A_curr)\n",
    "        \n",
    "        grads[f\"dW{i}\"] = (A_prev.T @ dZ) / m\n",
    "        grads[f\"db{i}\"] = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(params, grads, learning_rate, weight_decay=0.0):\n",
    "    \"\"\"\n",
    "    Updates params in-place with gradient descent step and optional weight decay (L2).\n",
    "    \"\"\"\n",
    "    for key in params:\n",
    "        if key.startswith(\"W\"):\n",
    "            # L2 penalty\n",
    "            params[key] -= learning_rate * (grads[f\"d{key}\"] + weight_decay * params[key])\n",
    "        elif key.startswith(\"b\"):\n",
    "            params[key] -= learning_rate * grads[f\"d{key}\"]\n",
    "    return params\n",
    "\n",
    "\n",
    "def train_one_epoch(X_train, y_train, params, num_hidden_layers, activation,\n",
    "                    batch_size, learning_rate, weight_decay=0.0):\n",
    "    \"\"\"\n",
    "    Trains for 1 epoch using mini-batch SGD.\n",
    "    Returns train_loss, train_acc for this epoch.\n",
    "    \"\"\"\n",
    "    N = X_train.shape[0]\n",
    "    permutation = np.random.permutation(N)\n",
    "    X_train = X_train[permutation]\n",
    "    y_train = y_train[permutation]\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Forward\n",
    "        probs, cache = forward_pass(X_batch, params, num_hidden_layers, activation)\n",
    "        loss = cross_entropy_loss(probs, y_batch)\n",
    "        total_loss += loss * len(X_batch)\n",
    "        \n",
    "        # Accuracy\n",
    "        pred_labels = np.argmax(probs, axis=1)\n",
    "        true_labels = np.argmax(y_batch, axis=1)\n",
    "        total_correct += np.sum(pred_labels == true_labels)\n",
    "        \n",
    "        # Backward\n",
    "        grads = backward_pass(X_batch, y_batch, params, cache, num_hidden_layers, activation)\n",
    "        \n",
    "        # Update\n",
    "        params = update_parameters(params, grads, learning_rate, weight_decay)\n",
    "    \n",
    "    # Compute average metrics\n",
    "    avg_loss = total_loss / N\n",
    "    avg_acc  = total_correct / N\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "\n",
    "def train():\n",
    "    # Start a new W&B run\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Load data\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data(val_split=0.1)\n",
    "    # One-hot\n",
    "    y_train_oh = one_hot_encode(y_train)\n",
    "    y_val_oh   = one_hot_encode(y_val)\n",
    "    y_test_oh  = one_hot_encode(y_test)\n",
    "    \n",
    "    # Create run name for clarity\n",
    "    run_name = f\"hl_{config.num_hidden_layers}_bs_{config.batch_size}_ac_{config.activation}\"\n",
    "    wandb.run.name = run_name\n",
    "    \n",
    "    # Initialize parameters\n",
    "    input_dim  = 784\n",
    "    output_dim = 10\n",
    "    params = initialize_parameters(\n",
    "        input_dim,\n",
    "        num_hidden_layers=config.num_hidden_layers,\n",
    "        hidden_size=config.hidden_layer_size,\n",
    "        output_dim=output_dim,\n",
    "        weight_init=config.weight_init\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            X_train, y_train_oh, \n",
    "            params,\n",
    "            num_hidden_layers=config.num_hidden_layers,\n",
    "            activation=config.activation,\n",
    "            batch_size=config.batch_size,\n",
    "            learning_rate=config.learning_rate,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Validation metrics\n",
    "        probs_val, _ = forward_pass(X_val, params, config.num_hidden_layers, config.activation)\n",
    "        val_loss = cross_entropy_loss(probs_val, y_val_oh)\n",
    "        val_acc  = accuracy(probs_val, y_val_oh)\n",
    "        \n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "    \n",
    "    # Evaluate on test set once\n",
    "    probs_test, _ = forward_pass(X_test, params, config.num_hidden_layers, config.activation)\n",
    "    test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "    test_acc  = accuracy(probs_test, y_test_oh)\n",
    "    wandb.log({\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"fashion_mnist_sweep_example\",  # or any descriptive name\n",
    "    \"method\": \"random\",  # can also be \"grid\" or \"bayes\"\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_acc\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"epochs\": {\n",
    "            \"values\": [5, 10]\n",
    "        },\n",
    "        \"num_hidden_layers\": {\n",
    "            \"values\": [3, 4, 5]\n",
    "        },\n",
    "        \"hidden_layer_size\": {\n",
    "            \"values\": [32, 64, 128]\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"values\": [0.0, 0.0005, 0.5]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [1e-3, 1e-4]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [16, 32, 64]\n",
    "        },\n",
    "        \"weight_init\": {\n",
    "            \"values\": [\"random\", \"xavier\"]\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"values\": [\"sigmoid\", \"tanh\", \"relu\"]\n",
    "        },\n",
    "        \"optimizer\": {\"values\": [\"sgd\", \"momentum\", \"rmsprop\", \"adam\"]}  # New Field for Optimizers\n",
    "\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Code: Optimizer Classes\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                params[key] -= self.lr * grads[key]\n",
    "        return params\n",
    "\n",
    "class Momentum:\n",
    "    def __init__(self, lr, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = {}\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                self.v[key] = self.momentum * self.v[key] + self.lr * grads[key]\n",
    "                params[key] -= self.v[key]\n",
    "        return params\n",
    "\n",
    "class RMSprop:\n",
    "    def __init__(self, lr, decay_rate=0.99, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.cache = {}\n",
    "    def update(self, params, grads, t=None):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.cache:\n",
    "                    self.cache[key] = np.zeros_like(params[key])\n",
    "                self.cache[key] = self.decay_rate * self.cache[key] + (1 - self.decay_rate) * (grads[key] ** 2)\n",
    "                params[key] -= self.lr * grads[key] / (np.sqrt(self.cache[key]) + self.epsilon)\n",
    "        return params\n",
    "\n",
    "class Adam:\n",
    "    def __init__(self, lr, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = {}\n",
    "        self.v = {}\n",
    "    def update(self, params, grads, t):\n",
    "        for key in params:\n",
    "            if key in grads:\n",
    "                if key not in self.m:\n",
    "                    self.m[key] = np.zeros_like(params[key])\n",
    "                if key not in self.v:\n",
    "                    self.v[key] = np.zeros_like(params[key])\n",
    "                self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n",
    "                self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key] ** 2)\n",
    "                m_hat = self.m[key] / (1 - self.beta1 ** t)\n",
    "                v_hat = self.v[key] / (1 - self.beta2 ** t)\n",
    "                params[key] -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated train_one_epoch() function\n",
    "\n",
    "def train_one_epoch(X_train, y_train, params, num_hidden_layers, activation,\n",
    "                    batch_size, learning_rate, weight_decay=0.0, optimizer=\"sgd\",\n",
    "                    beta1=0.9, beta2=0.999, epsilon=1e-8, momentum=0.9, decay_rate=0.99):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains for 1 epoch using mini-batch gradient descent.\n",
    "    Supports multiple optimizers: SGD, Momentum, Nesterov, RMSprop, Adam, Nadam.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data & labels (one-hot encoded).\n",
    "        params: Model parameters.\n",
    "        num_hidden_layers: Number of hidden layers.\n",
    "        activation: Activation function (\"relu\", \"sigmoid\", \"tanh\").\n",
    "        batch_size: Mini-batch size.\n",
    "        learning_rate: Learning rate for optimization.\n",
    "        weight_decay: L2 regularization term (if used).\n",
    "        optimizer: String defining optimizer type (\"sgd\", \"momentum\", \"nesterov\", \"rmsprop\", \"adam\", \"nadam\").\n",
    "        beta1, beta2: Adam/Nadam exponential decay rates.\n",
    "        epsilon: Small constant for numerical stability (Adam/Nadam).\n",
    "        momentum: Momentum factor for momentum-based optimizers.\n",
    "        decay_rate: Decay factor for RMSprop.\n",
    "\n",
    "    Returns:\n",
    "        train_loss, train_acc: Loss & accuracy for this epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    N = X_train.shape[0]\n",
    "    permutation = np.random.permutation(N)\n",
    "    X_train = X_train[permutation]\n",
    "    y_train = y_train[permutation]\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "\n",
    "    # Initialize optimizer-specific caches\n",
    "    v = {}  # Momentum/Nesterov\n",
    "    s = {}  # RMSprop, Adam, Nadam\n",
    "    t = 0   # Adam/Nadam time step counter\n",
    "    \n",
    "    for key in params:\n",
    "        v[key] = np.zeros_like(params[key])  # Initialize momentum term\n",
    "        s[key] = np.zeros_like(params[key])  # Initialize second moment term\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Forward Pass\n",
    "        probs, cache = forward_pass(X_batch, params, num_hidden_layers, activation)\n",
    "        loss = cross_entropy_loss(probs, y_batch)\n",
    "        total_loss += loss * len(X_batch)\n",
    "\n",
    "        # Accuracy\n",
    "        pred_labels = np.argmax(probs, axis=1)\n",
    "        true_labels = np.argmax(y_batch, axis=1)\n",
    "        total_correct += np.sum(pred_labels == true_labels)\n",
    "        \n",
    "        # Backward Pass\n",
    "        grads = backward_pass(X_batch, y_batch, params, cache, num_hidden_layers, activation)\n",
    "        \n",
    "        # Update parameters based on optimizer choice\n",
    "        t += 1  # Increment time step for Adam/Nadam\n",
    "        \n",
    "        for key in params:\n",
    "            if key.startswith(\"W\"):\n",
    "                if optimizer == \"sgd\":\n",
    "                    # Vanilla SGD\n",
    "                    params[key] -= learning_rate * (grads[f\"d{key}\"] + weight_decay * params[key])\n",
    "                \n",
    "                elif optimizer == \"momentum\":\n",
    "                    # Momentum-based SGD\n",
    "                    v[key] = momentum * v[key] - learning_rate * grads[f\"d{key}\"]\n",
    "                    params[key] += v[key]\n",
    "\n",
    "                elif optimizer == \"nesterov\":\n",
    "                    # Nesterov Accelerated Gradient (Lookahead step)\n",
    "                    v_prev = v[key]\n",
    "                    v[key] = momentum * v[key] - learning_rate * grads[f\"d{key}\"]\n",
    "                    params[key] += -momentum * v_prev + (1 + momentum) * v[key]\n",
    "                \n",
    "                elif optimizer == \"rmsprop\":\n",
    "                    # RMSprop\n",
    "                    s[key] = decay_rate * s[key] + (1 - decay_rate) * (grads[f\"d{key}\"] ** 2)\n",
    "                    params[key] -= learning_rate * grads[f\"d{key}\"] / (np.sqrt(s[key]) + epsilon)\n",
    "\n",
    "                elif optimizer == \"adam\":\n",
    "                    # Adam optimizer\n",
    "                    v[key] = beta1 * v[key] + (1 - beta1) * grads[f\"d{key}\"]\n",
    "                    s[key] = beta2 * s[key] + (1 - beta2) * (grads[f\"d{key}\"] ** 2)\n",
    "                    v_corrected = v[key] / (1 - beta1 ** t)\n",
    "                    s_corrected = s[key] / (1 - beta2 ** t)\n",
    "                    params[key] -= learning_rate * v_corrected / (np.sqrt(s_corrected) + epsilon)\n",
    "\n",
    "                elif optimizer == \"nadam\":\n",
    "                    # Nadam (Adam + Nesterov momentum)\n",
    "                    v[key] = beta1 * v[key] + (1 - beta1) * grads[f\"d{key}\"]\n",
    "                    s[key] = beta2 * s[key] + (1 - beta2) * (grads[f\"d{key}\"] ** 2)\n",
    "                    v_corrected = v[key] / (1 - beta1 ** t)\n",
    "                    s_corrected = s[key] / (1 - beta2 ** t)\n",
    "                    nadam_update = beta1 * v_corrected + (1 - beta1) * grads[f\"d{key}\"] / (1 - beta1 ** t)\n",
    "                    params[key] -= learning_rate * nadam_update / (np.sqrt(s_corrected) + epsilon)\n",
    "\n",
    "            elif key.startswith(\"b\"):\n",
    "                # Bias updates (same update rule as weights, but without L2 regularization)\n",
    "                params[key] -= learning_rate * grads[f\"d{key}\"]\n",
    "\n",
    "    # Compute average metrics\n",
    "    avg_loss = total_loss / N\n",
    "    avg_acc  = total_correct / N\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "\n",
    "def train():\n",
    "    # Start a new W&B run\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Load data\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data(val_split=0.1)\n",
    "    # One-hot\n",
    "    y_train_oh = one_hot_encode(y_train)\n",
    "    y_val_oh   = one_hot_encode(y_val)\n",
    "    y_test_oh  = one_hot_encode(y_test)\n",
    "    \n",
    "    # Create run name for clarity\n",
    "    run_name = f\"hl_{config.num_hidden_layers}_bs_{config.batch_size}_ac_{config.activation}\"\n",
    "    wandb.run.name = run_name\n",
    "    \n",
    "    # Initialize parameters\n",
    "    input_dim  = 784\n",
    "    output_dim = 10\n",
    "    params = initialize_parameters(\n",
    "        input_dim,\n",
    "        num_hidden_layers=config.num_hidden_layers,\n",
    "        hidden_size=config.hidden_layer_size,\n",
    "        output_dim=output_dim,\n",
    "        weight_init=config.weight_init\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            X_train, y_train_oh, \n",
    "            params,\n",
    "            num_hidden_layers=config.num_hidden_layers,\n",
    "            activation=config.activation,\n",
    "            batch_size=config.batch_size,\n",
    "            learning_rate=config.learning_rate,\n",
    "            weight_decay=config.weight_decay,\n",
    "            optimizer=config.optimizer,\n",
    "            beta1=0.9, beta2=0.999, epsilon=1e-8, momentum=0.9, decay_rate=0.99\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Validation metrics\n",
    "        probs_val, _ = forward_pass(X_val, params, config.num_hidden_layers, config.activation)\n",
    "        val_loss = cross_entropy_loss(probs_val, y_val_oh)\n",
    "        val_acc  = accuracy(probs_val, y_val_oh)\n",
    "        \n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "    \n",
    "    # Evaluate on test set once\n",
    "    probs_test, _ = forward_pass(X_test, params, config.num_hidden_layers, config.activation)\n",
    "    test_loss = cross_entropy_loss(probs_test, y_test_oh)\n",
    "    test_acc  = accuracy(probs_test, y_test_oh)\n",
    "    wandb.log({\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc\n",
    "    })\n",
    "    \n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: uz2tgs7m\n",
      "Sweep URL: https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ovdja3ua with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_105922-ovdja3ua</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ovdja3ua' target=\"_blank\">upbeat-sweep-1</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ovdja3ua' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ovdja3ua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_acc</td><td>0.2001</td></tr><tr><td>test_loss</td><td>1.85787</td></tr><tr><td>train_acc</td><td>0.1995</td></tr><tr><td>train_loss</td><td>1.86691</td></tr><tr><td>val_acc</td><td>0.19617</td></tr><tr><td>val_loss</td><td>1.85602</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_4_bs_32_ac_sigmoid</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ovdja3ua' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ovdja3ua</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_105922-ovdja3ua/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nnshzov6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_105944-nnshzov6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/nnshzov6' target=\"_blank\">lemon-sweep-2</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/nnshzov6' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/nnshzov6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_acc</td><td>0.1</td></tr><tr><td>test_loss</td><td>2.30266</td></tr><tr><td>train_acc</td><td>0.10013</td></tr><tr><td>train_loss</td><td>2.30266</td></tr><tr><td>val_acc</td><td>0.09833</td></tr><tr><td>val_loss</td><td>2.30282</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_32_ac_sigmoid</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/nnshzov6' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/nnshzov6</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_105944-nnshzov6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6tokstu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110000-6tokstu5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/6tokstu5' target=\"_blank\">leafy-sweep-3</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/6tokstu5' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/6tokstu5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.8521</td></tr><tr><td>test_loss</td><td>0.42071</td></tr><tr><td>train_acc</td><td>0.86407</td></tr><tr><td>train_loss</td><td>0.3828</td></tr><tr><td>val_acc</td><td>0.8635</td></tr><tr><td>val_loss</td><td>0.39035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_5_bs_32_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/6tokstu5' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/6tokstu5</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110000-6tokstu5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qdfguzug with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110028-qdfguzug</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/qdfguzug' target=\"_blank\">summer-sweep-4</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/qdfguzug' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/qdfguzug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.8767</td></tr><tr><td>test_loss</td><td>0.35805</td></tr><tr><td>train_acc</td><td>0.89657</td></tr><tr><td>train_loss</td><td>0.28088</td></tr><tr><td>val_acc</td><td>0.88417</td></tr><tr><td>val_loss</td><td>0.32334</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_4_bs_16_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/qdfguzug' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/qdfguzug</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110028-qdfguzug/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1ubbotc3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110149-1ubbotc3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/1ubbotc3' target=\"_blank\">whole-sweep-5</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/1ubbotc3' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/1ubbotc3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.1</td></tr><tr><td>test_loss</td><td>2.30259</td></tr><tr><td>train_acc</td><td>0.09917</td></tr><tr><td>train_loss</td><td>2.30266</td></tr><tr><td>val_acc</td><td>0.09333</td></tr><tr><td>val_loss</td><td>2.30272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_16_ac_sigmoid</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/1ubbotc3' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/1ubbotc3</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110149-1ubbotc3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ksdim6gx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110257-ksdim6gx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ksdim6gx' target=\"_blank\">gentle-sweep-6</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ksdim6gx' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ksdim6gx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_acc</td><td>0.8008</td></tr><tr><td>test_loss</td><td>0.5619</td></tr><tr><td>train_acc</td><td>0.80633</td></tr><tr><td>train_loss</td><td>0.5522</td></tr><tr><td>val_acc</td><td>0.81183</td></tr><tr><td>val_loss</td><td>0.54076</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_16_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ksdim6gx' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/ksdim6gx</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110257-ksdim6gx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0gqu6wpz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110314-0gqu6wpz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/0gqu6wpz' target=\"_blank\">avid-sweep-7</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/0gqu6wpz' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/0gqu6wpz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_acc</td><td>0.82</td></tr><tr><td>test_loss</td><td>0.51844</td></tr><tr><td>train_acc</td><td>0.82459</td></tr><tr><td>train_loss</td><td>0.50206</td></tr><tr><td>val_acc</td><td>0.83267</td></tr><tr><td>val_loss</td><td>0.48675</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_16_ac_tanh</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/0gqu6wpz' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/0gqu6wpz</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110314-0gqu6wpz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kzvf60au with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110352-kzvf60au</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/kzvf60au' target=\"_blank\">genial-sweep-8</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/kzvf60au' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/kzvf60au</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.8804</td></tr><tr><td>test_loss</td><td>0.34373</td></tr><tr><td>train_acc</td><td>0.9075</td></tr><tr><td>train_loss</td><td>0.2432</td></tr><tr><td>val_acc</td><td>0.89217</td></tr><tr><td>val_loss</td><td>0.31043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_64_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/kzvf60au' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/kzvf60au</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110352-kzvf60au/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: it57ss9l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110521-it57ss9l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/it57ss9l' target=\"_blank\">leafy-sweep-9</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/it57ss9l' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/it57ss9l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.6255</td></tr><tr><td>test_loss</td><td>0.91256</td></tr><tr><td>train_acc</td><td>0.63702</td></tr><tr><td>train_loss</td><td>0.90051</td></tr><tr><td>val_acc</td><td>0.63417</td></tr><tr><td>val_loss</td><td>0.89718</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_4_bs_64_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/it57ss9l' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/it57ss9l</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110521-it57ss9l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u6g30sbx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/snehal/Downloads/dl_ass1/wandb/run-20250306_110538-u6g30sbx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/u6g30sbx' target=\"_blank\">dry-sweep-10</a></strong> to <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/sweeps/uz2tgs7m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/u6g30sbx' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/u6g30sbx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_acc</td><td></td></tr><tr><td>test_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_acc</td><td>0.8509</td></tr><tr><td>test_loss</td><td>0.42796</td></tr><tr><td>train_acc</td><td>0.86602</td></tr><tr><td>train_loss</td><td>0.38314</td></tr><tr><td>val_acc</td><td>0.861</td></tr><tr><td>val_loss</td><td>0.39465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hl_3_bs_32_ac_relu</strong> at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/u6g30sbx' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1/runs/u6g30sbx</a><br> View project at: <a href='https://wandb.ai/snehalma23m020-iit-madras/DLassignment1' target=\"_blank\">https://wandb.ai/snehalma23m020-iit-madras/DLassignment1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250306_110538-u6g30sbx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7\n",
    "\n",
    "# 7a) Log in to W&B if not already\n",
    "wandb.login()\n",
    "\n",
    "# 7b) Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DLassignment1\")  # set your W&B project name\n",
    "\n",
    "# 7c) Run the sweep\n",
    "#    count=10 => run 10 random trials from the hyperparameter space\n",
    "wandb.agent(sweep_id, function=train, count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
